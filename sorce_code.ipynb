{"cells":[{"cell_type":"markdown","metadata":{"id":"riVZOD4Erd6g"},"source":["## データの読み込みと加工"]},{"cell_type":"markdown","metadata":{"id":"ybMWRo94pYiJ"},"source":["### データの読み込み"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ause6fZrh6v"},"outputs":[],"source":["from pandas._libs.tslibs.vectorized import normalize_i8_timestamps\n","import io\n","import pandas as pd\n","import csv\n","import time\n","\n","start = time.perf_counter() #実行時間のカウント開始\n","\n","# 列名のついた配列にデータを格納\n","f2 = \"(データのパス)\"\n","col_names = [ 'c{0:02d}'.format(i) for i in range(402) ]\n","auto = pd.read_csv(f2,names=col_names)\n","\n","print(time.perf_counter() - start)#実行時間のカウント終了、表示\n","auto"]},{"cell_type":"markdown","metadata":{"id":"XTlLLLyubC72"},"source":["### 必要のない列を削除"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PJLUYLkp4vCB"},"outputs":[],"source":["# # # 必要のない列を削除(説明変数：z座標、ワイヤー座標、ドリフト時間)\n","delete_names = ['c01','c05','c09']\n","for i in range(3,100):\n","  delete_names.append('c%d' % (1+4*i)) #面番号\n","\n","# # 必要のない列を削除(説明変数：ワイヤー座標、ドリフト時間)\n","# delete_names = ['c01','c02','c05','c06','c09','c10']\n","# for i in range(3,100):\n","#   delete_names.append('c%d' % (1+4*i))\n","#   delete_names.append('c%d' % (2+4*i)) #z座標\n","\n","# # 必要のない列を削除(説明変数：z座標、ワイヤー座標)\n","# delete_names = ['c01','c04','c05','c08','c09','c400']\n","# for i in range(3,100):\n","#   delete_names.append('c%d' % (1+4*i))\n","#   delete_names.append('c%d' % (4*i)) #ドリフト時間\n","\n","# # 必要のない列を削除(説明変数：z座標、ドリフト時間)\n","# delete_names = ['c01','c03','c04','c05','c07','c09','c11']\n","# for i in range(3,100):\n","#   delete_names.append('c%d' % (1+4*i))\n","#   delete_names.append('c%d' % (3+4*i)) #ワイヤー座標\n","\n","# # 必要のない列を削除(説明変数：z座標)\n","# delete_names = ['c01','c03','c04','c05','c07','c08','c09','c11','c400']\n","# for i in range(3,100):\n","#   delete_names.append('c%d' % (1+4*i))\n","#   delete_names.append('c%d' % (3+4*i))\n","#   delete_names.append('c%d' % (4*i))\n","\n","# # 必要のない列を削除(説明変数：ワイヤー座標)\n","# delete_names = ['c01','c02','c04','c05','c06','c08','c09','c10','c400']\n","# for i in range(3,100):\n","#   delete_names.append('c%d' % (1+4*i))\n","#   delete_names.append('c%d' % (2+4*i))\n","#   delete_names.append('c%d' % (4*i))\n","\n","# # 必要のない列を削除(説明変数：ドリフト時間)\n","# delete_names = ['c01','c02','c03','c05','c06','c07','c09','c10','c11']\n","# for i in range(3,100):\n","#   delete_names.append('c%d' % (1+4*i))\n","#   delete_names.append('c%d' % (2+4*i))\n","#   delete_names.append('c%d' % (3+4*i))\n","\n","\n","auto = auto.drop(delete_names, axis=1) #この行で削除を行っている。上では、どの列を削除するかをしている。\n","\n","# # ランダムにデータを並び替え（なくてもよい）\n","auto = auto.sample(frac=1, ignore_index=True, random_state=42)\n","\n","## リアルデータでtrack有り無しのみを判定したいとき\n","# c401列で0以外の値を持つ行をすべて1に変更\n","auto.loc[auto['c401'] != 0, 'c401'] = 1\n","\n","print(auto)"]},{"cell_type":"markdown","metadata":{"id":"5EEWbcyxTCXm"},"source":["### データのクラス割合を調整"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zWUqM_6lTKNk"},"outputs":[],"source":["import pandas as pd\n","from sklearn.utils import resample\n","\n","# 0と1のデータをそれぞれ抽出\n","data_0 = auto[auto['c401'] == 0]\n","data_1 = auto[auto['c401'] == 1]\n","\n","# データ数を取得\n","count_0 = len(data_0)\n","count_1 = len(data_1)\n","\n","# サンプリング後の目標データ数を設定\n","target_count = min(100000, min(count_0, count_1))  # 最大200,000になるように調整\n","\n","# resample関数を使ってサンプリング\n","sampled_data_0 = resample(data_0, replace=False, n_samples=target_count, random_state=42)\n","sampled_data_1 = resample(data_1, replace=False, n_samples=target_count, random_state=42)\n","\n","# 新しいデータフレームに結合\n","auto = pd.concat([sampled_data_0, sampled_data_1])\n","\n","# 調整前と調整後のトラック有り無しのデータ数を表示\n","print(f'Original 0s: {count_0}, Original 1s: {count_1}')\n","print(f'Sampled 0s: {target_count}, Sampled 1s: {target_count}')"]},{"cell_type":"markdown","metadata":{"id":"ATh0oVYJaT4N"},"source":["### 入力層に取り込む列のラベルのリストを作成"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5PmrBoJLQMZ"},"outputs":[],"source":["col_names = auto.columns.values.tolist()\n","col_names.remove('c00') #面番号\n","col_names.remove('c401') #正解ラベル\n","print(col_names)"]},{"cell_type":"markdown","metadata":{"id":"kEoYBkzBEvIz"},"source":["## tensowflowで行う機械学習"]},{"cell_type":"markdown","metadata":{"id":"-9eT5H2KZ5DE"},"source":["### パッケージの読み込み"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3798,"status":"ok","timestamp":1707726237835,"user":{"displayName":"Kyotaro Nishi","userId":"13435910157482113072"},"user_tz":-540},"id":"-xS_r7fUZ3tu","outputId":"9d25beee-63cf-4260-9cc7-449ff3557e7f"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.15.0\n"]}],"source":["import sys\n","sys.setrecursionlimit(2000)\n","import numpy as np\n","from __future__ import print_function\n","from matplotlib import pyplot as plt\n","import tensorflow as tf\n","print(tf.__version__)\n","from tensorflow.python.client import device_lib\n","import tensorflow.keras as kera\n","from tensorflow.keras import backend\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import RMSprop\n","from sklearn.model_selection import train_test_split\n","import hyperopt\n","from hyperopt import fmin, tpe, hp\n","from sklearn.metrics import f1_score\n","from keras.callbacks import LearningRateScheduler"]},{"cell_type":"markdown","metadata":{"id":"UZ2MboixGuE7"},"source":["### 学習用データと検証用データに分割"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ze63rJrVw29M"},"outputs":[],"source":["\n","num_classes = 2\n","\n","\n","X = auto[col_names] # 説明変数の列の指定\n","y = auto['c401']\n","\n","# 列\"c00\"を別の変数に保存（データ番号の保存のため）\n","c00_info = auto['c00']\n","\n","# 訓練データとテストデータに分ける\n","x_train, x_test, y_train, y_test, c00_train, c00_test = train_test_split(X, y, c00_info, test_size=0.3, random_state=0)\n","y_train = kera.utils.to_categorical(y_train, num_classes)\n","y_test = kera.utils.to_categorical(y_test, num_classes)"]},{"cell_type":"markdown","metadata":{"id":"nsVCpIH0Qr03"},"source":["#### ハイパーパラメータ探索"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zep5Zp_tQy8G"},"outputs":[],"source":["start = time.perf_counter()\n","epochs = 20\n","\n","# Step 1: ハイパーパラメータ探索範囲を定義\n","space = {\n","    'batch_size': hp.choice('batch_size', [64, 128, 256, 512]), #バッチサイズ\n","    'layers': hp.randint('layers', 30) + 1,  # 中間層\n","    'neurons': hp.choice('neurons', [64, 128, 256, 512,1024]), #ニューロン数\n","    'lr': hp.loguniform('lr', -9, -2), #学習率\n","}\n","\n","# Step 2: 目的関数を定義\n","def objective(params):\n","    batch_size = params['batch_size']\n","    layers = params['layers']\n","    neurons = params['neurons']\n","    lr = params['lr']\n","\n","    class_weights = {0: 1.0, 1: 5.0}  # 重みを調整\n","\n","    # モデルの構築と訓練\n","    model = Sequential()\n","    model.add(Dense(300, activation='relu', input_shape=(300,))) #データの入力数を指定\n","    model.add(Dropout(0.2))\n","    for i in range(1, layers-1):\n","        model.add(Dense(neurons, activation='relu'))\n","        model.add(Dropout(0.2))\n","    model.add(Dense(num_classes, activation='softmax'))\n","\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer=kera.optimizers.RMSprop(lr=lr),\n","                  metrics=['accuracy'])\n","\n","    history = model.fit(x_train, y_train,\n","                        batch_size=batch_size,\n","                        epochs=epochs,\n","                        verbose=0,\n","                        validation_data=(x_test, y_test),\n","                        class_weight=class_weights #重みづけ\n","    )\n","\n","    # F1スコアを評価指標\n","    y_pred = model.predict(x_test)\n","    y_pred_classes = np.argmax(y_pred, axis=1)\n","    y_true = np.argmax(y_test, axis=1)\n","    f1 = f1_score(y_true, y_pred_classes) # F1スコアを計算\n","\n","    return -f1  # 目的関数は最大化する必要があるため、負のF1スコアを返す\n","\n","# Step 3: hyperoptを使用して最適なハイパーパラメータを探索\n","best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=10)  # max_evalsで検証回数を指定\n","print(\"Best Hyperparameters:\", best)\n","\n","print(time.perf_counter() - start)"]},{"cell_type":"markdown","metadata":{"id":"BNz9kYRhv-ud"},"source":["#### 学習"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0FdYJ0l9Et-Z"},"outputs":[],"source":["start = time.perf_counter()\n","\n","#GPUの非決定的ランダム性を排除(再現性の確保)\n","tf.keras.utils.set_random_seed(1)\n","tf.config.experimental.enable_op_determinism()\n","\n","num_classes = 2\n","batch_size = 256\n","epochs = 8\n","layers = 21\n","neurons = 128\n","lr = 0.001393445233225502\n","\n","class_weights = {0: 1.0, 1: 6.0}  # class1の重みを調整\n","\n","model = Sequential()\n","\n","model.add(Dense(300, activation='relu', input_shape=(300,)))\n","model.add(Dropout(0.2))\n","\n","for i in range(1, layers-1, 1):\n","    model.add(Dense(neurons, activation='relu'))\n","    model.add(Dropout(0.2))\n","\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=kera.optimizers.RMSprop(lr=lr),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test),\n","                    class_weight=class_weights,\n",")\n","\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])\n","\n","# クラスごとの正答率を計算\n","y_pred = model.predict(x_test)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true = np.argmax(y_test, axis=1)\n","\n","class_accuracy = {}\n","for i in range(num_classes):\n","    class_indices = np.where(y_true == i)\n","    class_correct = np.sum(y_pred_classes[class_indices] == i)\n","    class_total = len(class_indices[0])\n","    class_accuracy[i] = class_correct / class_total\n","print('Class Accuracy:')\n","for i, acc in class_accuracy.items():\n","    print(f'Class {i}: {acc}')\n","\n","# F1スコアを計算\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true = np.argmax(y_test, axis=1)\n","f1 = f1_score(y_true, y_pred_classes)\n","print(\"f1_score\",f1)\n","\n","plt.plot(history.history['accuracy'], marker='.', label='acc')\n","plt.plot(history.history['val_accuracy'], marker='.', label='val_acc')\n","\n","plt.title('model accuracy')\n","plt.grid()\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.legend(loc='best')\n","plt.show()\n","\n","plt.plot(history.history['loss'], marker='.', label='loss')\n","plt.plot(history.history['val_loss'], marker='.', label='val_loss')\n","plt.title('model loss')\n","plt.grid()\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend(loc='best')\n","plt.show()\n","\n","print(time.perf_counter() - start)"]},{"cell_type":"markdown","metadata":{"id":"aA7MHrbcPKpf"},"source":["## おまけ"]},{"cell_type":"markdown","metadata":{"id":"kHCrLSyFv2DR"},"source":["### モデルの保存"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4saFfaO4udLb"},"outputs":[],"source":["import pickle\n","\n","# 構築したモデルの保存\n","filename = 'real_model.pkl'\n","pickle.dump(model,open(filename,'wb'))"]},{"cell_type":"markdown","metadata":{"id":"je1l4GZHSLwH"},"source":["### 正解・不正解データを保存"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3zjzWy0lRQbD"},"outputs":[],"source":["# Class 1で不正解のデータを抽出してファイルに保存\n","incorrect_indices = np.where((y_pred_classes != y_true) & (y_true == 1))[0]\n","incorrect_data = x_test.iloc[incorrect_indices]\n","incorrect_data.insert(0, 'c00', c00_test.iloc[incorrect_indices])  # c00列を追加\n","incorrect_data.to_csv('incorrect_data_class1.csv', index=False)\n","\n","# Class 1で正解のデータを抽出してファイルに保存\n","correct_indices = np.where((y_pred_classes == y_true) & (y_true == 1))[0]\n","correct_data = x_test.iloc[correct_indices]\n","correct_data.insert(0, 'c00', c00_test.iloc[correct_indices])  # c00列を追加\n","correct_data.to_csv('correct_data_class1.csv', index=False)\n","\n","# Class 0で正解のデータを抽出してファイルに保存\n","other_indices = np.where((y_pred_classes == y_true) & (y_true == 0))[0]\n","other_data = x_test.iloc[other_indices]\n","other_data.insert(0, 'c00', c00_test.iloc[other_indices])  # c00列を追加\n","other_data.to_csv('correct_data_class0.csv', index=False)\n","\n","# Class 0で不正解のデータを抽出してファイルに保存\n","other_indices = np.where((y_pred_classes != y_true) & (y_true == 0))[0]\n","other_data = x_test.iloc[other_indices]\n","other_data.insert(0, 'c00', c00_test.iloc[other_indices])  # c00列を追加\n","other_data.to_csv('incorrect_data_class0.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"qvvSqrSu2LIi"},"source":["### データ解析"]},{"cell_type":"markdown","metadata":{"id":"inC4XiJu0Kf7"},"source":["#### ヒット数別0の占有割合"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1kZSoASbwtCC"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# データを読み込む\n","incorrect_data_class1 = pd.read_csv('incorrect_data_class1.csv')\n","correct_data_class1 = pd.read_csv('correct_data_class1.csv')\n","incorrect_data_class0 = pd.read_csv('incorrect_data_class0.csv')\n","correct_data_class0 = pd.read_csv('correct_data_class0.csv')\n","\n","all_counts = pd.concat([incorrect_data_class1, correct_data_class1, incorrect_data_class0, correct_data_class0]) # 結合\n","\n","# 1ヒットごとの説明変数を1つにする\n","delete_names = ['c00','c02','c03','c06','c07','c10','c11']\n","for i in range(3,100):\n","  delete_names.append('c%d' % (2+4*i))\n","  delete_names.append('c%d' % (3+4*i))\n","\n","all_counts = all_counts.drop(delete_names, axis=1)\n","\n","# 各列ごとの0の占有率を計算する\n","zero_counts = all_counts.eq(0).sum(axis=0) / 60000\n","\n","plt.figure(figsize=(10, 6))\n","plt.hist(range(100), bins=100, weights=zero_counts, alpha=0.5, color='green')\n","\n","plt.xlabel('hit')\n","plt.ylabel('Frequency')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"GEiImIJajVHA"},"source":["#### ヒット数別正答率またはヒット数確率分布の分析"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RbhyIHIwjdMK"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# データを読み込む\n","incorrect_data_class1 = pd.read_csv('incorrect_data_class1.csv')\n","correct_data_class1 = pd.read_csv('correct_data_class1.csv')\n","incorrect_data_class0 = pd.read_csv('incorrect_data_class0.csv')\n","correct_data_class0 = pd.read_csv('correct_data_class0.csv')\n","\n","# 0を含むものの数をインデックスごとに数える\n","incorrect_counts_class1 = 100 - (incorrect_data_class1 == 0).sum(axis=1) / 3\n","correct_counts_class1 = 100 - (correct_data_class1 == 0).sum(axis=1) / 3\n","incorrect_counts_class0 = 100 - (incorrect_data_class0 == 0).sum(axis=1) / 3\n","correct_counts_class0 = 100 - (correct_data_class0 == 0).sum(axis=1) / 3\n","\n","print(incorrect_counts_class1)\n","\n","incorrect_countsByhit_class1 = []\n","correct_countsByhit_class1 = []\n","incorrect_countsByhit_class0 = []\n","correct_countsByhit_class0 = []\n","\n","for i in range(101):\n","    incorrect_countsByhit_class1.append((incorrect_counts_class1 == i).sum(axis=0))\n","    correct_countsByhit_class1.append((correct_counts_class1 == i).sum(axis=0))\n","    incorrect_countsByhit_class0.append((incorrect_counts_class0 == i).sum(axis=0))\n","    correct_countsByhit_class0.append((correct_counts_class0 == i).sum(axis=0))\n","\n","# all_counts = pd.concat([incorrect_counts_class1, correct_counts_class1, incorrect_counts_class0, correct_counts_class0])\n","class1_countsByhit = incorrect_countsByhit_class1 + correct_countsByhit_class1\n","class0_countsByhit = incorrect_countsByhit_class0 + correct_countsByhit_class0\n","\n","print(class1_countsByhit)\n","\n","# 正答率の計算\n","class1_countsByhit = [incorrect + correct for incorrect, correct in zip(incorrect_countsByhit_class1, correct_countsByhit_class1)]\n","class0_countsByhit = [incorrect + correct for incorrect, correct in zip(incorrect_countsByhit_class0, correct_countsByhit_class0)]\n","\n","# ゼロ割りを防ぐため、ゼロ除算の箇所はNaNに置き換える\n","class1_accuracyByhit = [correct / total if total != 0 else np.nan for correct, total in zip(correct_countsByhit_class1, class1_countsByhit)]\n","class0_accuracyByhit = [correct / total if total != 0 else np.nan for correct, total in zip(correct_countsByhit_class0, class0_countsByhit)]\n","\n","\n","#ヒット数別正答率\n","plt.figure(figsize=(10, 6))\n","plt.hist(range(101), bins=101, weights=class1_accuracyByhit, alpha=0.7, label='Class 1 Accuracy')\n","plt.hist(range(101), bins=101, weights=class0_accuracyByhit, alpha=0.5, label='Class 0 Accuracy')\n","plt.xlabel('Index')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.hlines(y=0.5, xmin=0, xmax=100, alpha=0.5, color='black', linestyle='--')\n","plt.vlines(x=18, ymin=0, ymax=1, color='red', linestyle='--')\n","plt.show()\n","\n","# ヒット数確率分布\n","# plt.figure(figsize=(10, 6))\n","# plt.hist(range(101), bins=101, weights=class1_countsByhit, alpha=0.7, label='Class 1 Accuracy')\n","# plt.hist(range(101), bins=101, weights=class0_countsByhit, alpha=0.5, label='Class 0 Accuracy')\n","# plt.xlabel('Index')\n","# plt.ylabel('probability')\n","# plt.legend()\n","# plt.vlines(x=18, ymin=0, ymax=1, color='red', linestyle='--')\n","# plt.show()\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMzuO5Oiph46p2Ug7G7T3JR","collapsed_sections":["riVZOD4Erd6g","ybMWRo94pYiJ","XTlLLLyubC72","5EEWbcyxTCXm","ATh0oVYJaT4N","kEoYBkzBEvIz","-9eT5H2KZ5DE","UZ2MboixGuE7","aA7MHrbcPKpf","kHCrLSyFv2DR","je1l4GZHSLwH","pHNow_OtjMGS","inC4XiJu0Kf7","GEiImIJajVHA"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
